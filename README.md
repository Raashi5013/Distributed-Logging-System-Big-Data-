Distributed Logging System - Big data project
This project implements a Distributed Logging System designed for microservices-based architectures, aimed at improving observability, fault detection, and log traceability. It features a scalable pipeline where multiple independent microservices (or nodes) generate structured logs and periodic heartbeat signals to indicate their operational status. Each microservice sends its logs through a log accumulator, which formats and forwards them to a centralized Pub-Sub system (Apache Kafka) for real-time streaming, decoupling producers from consumers.

Logs are classified into levels—INFO, WARN, and ERROR—and enriched with metadata such as node ID, timestamp, service name, and message type. A central consumer service stores these logs in Elasticsearch, supporting fast querying and indexing. Logs with severity WARN or ERROR trigger immediate alerts, allowing for proactive issue resolution. Additionally, a heartbeat monitoring service continuously checks for node availability, raising alerts if any node fails to send heartbeats within a configured interval.

This system demonstrates key concepts from distributed systems and cloud-native logging, such as message brokering, log enrichment, failure detection, and real-time alerting. Built using tools like Kafka, Elasticsearch, Fluentd, and Python, it provides a robust, end-to-end solution for centralized logging in distributed environments.
